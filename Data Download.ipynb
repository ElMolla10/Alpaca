{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMAi3UMClmtZ7/ACy6yYwLX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import {z} from \"zod\";\n","import {Agent, AgentInputItem, Runner } from \"@openai/agents\";\n","\n","const StocksSchema = z.object({});\n","const stocks = new Agent({\n","  name: \"Stocks\",\n","  instructions: \"You will search up the latest news on Apple, Microsoft and Google stocks and return a small analysis on whether to buy/sell/hold stocsk\",\n","  model: \"gpt-5-nano\",\n","  outputType: StocksSchema,\n","  modelSettings: {\n","    reasoning: {\n","      effort: \"low\"\n","    },\n","    store: true\n","  }\n","});\n","\n","type WorkflowInput = { input_as_text: string };\n","\n","\n","// Main code entrypoint\n","export const runWorkflow = async (workflow: WorkflowInput) => {\n","  const conversationHistory: AgentInputItem[] = [\n","    {\n","      role: \"user\",\n","      content: [\n","        {\n","          type: \"input_text\",\n","          text: workflow.input_as_text\n","        }\n","      ]\n","    }\n","  ];\n","  const runner = new Runner({\n","    traceMetadata: {\n","      __trace_source__: \"agent-builder\",\n","      workflow_id: \"wf_68e53cd07cd48190bb6c10849dc076e303d07c1e123f4f78\"\n","    }\n","  });\n","  const stocksResultTemp = await runner.run(\n","    stocks,\n","    [\n","      ...conversationHistory\n","    ]\n","  );\n","  conversationHistory.push(...stocksResultTemp.newItems.map((item) => item.rawItem));\n","\n","  if (!stocksResultTemp.finalOutput) {\n","      throw new Error(\"Agent result is undefined\");\n","  }\n","\n","  const stocksResult = {\n","    output_text: JSON.stringify(stocksResultTemp.finalOutput),\n","    output_parsed: stocksResultTemp.finalOutput\n","  };\n","}\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"VSa0lIcMeJcw","executionInfo":{"status":"error","timestamp":1760127751476,"user_tz":-180,"elapsed":15,"user":{"displayName":"Mohamed Ehab","userId":"16063572679742729614"}},"outputId":"dc4ed223-8f89-456e-8540-572fd0bbb2fb"},"execution_count":1,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (ipython-input-852565369.py, line 1)","traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-852565369.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    import {z} from \"zod\";\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"ad79dd74","executionInfo":{"status":"aborted","timestamp":1760127751483,"user_tz":-180,"elapsed":266,"user":{"displayName":"Mohamed Ehab","userId":"16063572679742729614"}}},"source":["!pip install -q pandas_ta"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oGJ5dxjpK2BC","executionInfo":{"status":"ok","timestamp":1760127882776,"user_tz":-180,"elapsed":130988,"user":{"displayName":"Mohamed Ehab","userId":"16063572679742729614"}},"outputId":"dcce22a7-84f2-432e-e16c-48271882659c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","[DL] AAPL: hour 2020-10-10→2025-10-10\n","[DL] AAPL: 20043 rows\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-542906488.py:127: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df[\"vwap\"] = df[\"vwap\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n"]},{"output_type":"stream","name":"stdout","text":["[SAVE] AAPL: /content/drive/MyDrive/polygon_hourly_5y_multi/AAPL_hourly_last5y_selected_features.csv  rows=20024\n","[DL] MSFT: hour 2020-10-10→2025-10-10\n","[DL] MSFT: 20028 rows\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-542906488.py:127: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df[\"vwap\"] = df[\"vwap\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n"]},{"output_type":"stream","name":"stdout","text":["[SAVE] MSFT: /content/drive/MyDrive/polygon_hourly_5y_multi/MSFT_hourly_last5y_selected_features.csv  rows=20009\n","[DL] NVDA: hour 2020-10-10→2025-10-10\n","[DL] NVDA: 19961 rows\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-542906488.py:127: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df[\"vwap\"] = df[\"vwap\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n"]},{"output_type":"stream","name":"stdout","text":["[SAVE] NVDA: /content/drive/MyDrive/polygon_hourly_5y_multi/NVDA_hourly_last5y_selected_features.csv  rows=19942\n","[DL] AMD: hour 2020-10-10→2025-10-10\n","[DL] AMD: 20037 rows\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-542906488.py:127: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df[\"vwap\"] = df[\"vwap\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n"]},{"output_type":"stream","name":"stdout","text":["[SAVE] AMD: /content/drive/MyDrive/polygon_hourly_5y_multi/AMD_hourly_last5y_selected_features.csv  rows=20018\n","[DL] JPM: hour 2020-10-10→2025-10-10\n","[DL] JPM: 17875 rows\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-542906488.py:127: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df[\"vwap\"] = df[\"vwap\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n"]},{"output_type":"stream","name":"stdout","text":["[SAVE] JPM: /content/drive/MyDrive/polygon_hourly_5y_multi/JPM_hourly_last5y_selected_features.csv  rows=17856\n","[DL] GS: hour 2020-10-10→2025-10-10\n","[DL] GS: 15191 rows\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-542906488.py:127: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df[\"vwap\"] = df[\"vwap\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n"]},{"output_type":"stream","name":"stdout","text":["[SAVE] GS: /content/drive/MyDrive/polygon_hourly_5y_multi/GS_hourly_last5y_selected_features.csv  rows=15172\n","[DL] XOM: hour 2020-10-10→2025-10-10\n","[DL] XOM: 19339 rows\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-542906488.py:127: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df[\"vwap\"] = df[\"vwap\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n"]},{"output_type":"stream","name":"stdout","text":["[SAVE] XOM: /content/drive/MyDrive/polygon_hourly_5y_multi/XOM_hourly_last5y_selected_features.csv  rows=19320\n","[DL] CVX: hour 2020-10-10→2025-10-10\n","[DL] CVX: 17883 rows\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-542906488.py:127: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df[\"vwap\"] = df[\"vwap\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n"]},{"output_type":"stream","name":"stdout","text":["[SAVE] CVX: /content/drive/MyDrive/polygon_hourly_5y_multi/CVX_hourly_last5y_selected_features.csv  rows=17864\n","[DL] PG: hour 2020-10-10→2025-10-10\n","[DL] PG: 15034 rows\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-542906488.py:127: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df[\"vwap\"] = df[\"vwap\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n"]},{"output_type":"stream","name":"stdout","text":["[SAVE] PG: /content/drive/MyDrive/polygon_hourly_5y_multi/PG_hourly_last5y_selected_features.csv  rows=15015\n","[DL] KO: hour 2020-10-10→2025-10-10\n","[DL] KO: 18865 rows\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-542906488.py:127: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n","  df[\"vwap\"] = df[\"vwap\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n"]},{"output_type":"stream","name":"stdout","text":["[SAVE] KO: /content/drive/MyDrive/polygon_hourly_5y_multi/KO_hourly_last5y_selected_features.csv  rows=18846\n","[DONE] Manifest saved: /content/drive/MyDrive/polygon_hourly_5y_multi/download_manifest.json\n","[SUMMARY] ok=10 err=0\n"]}],"source":["# ===========================\n","# Polygon Data Downloader (5y Hourly) + Selected Features for MULTIPLE Tickers\n","# ===========================\n","\n","# Colab/Drive + libs\n","import os, time, math, json, requests\n","import pandas as pd\n","from datetime import datetime, timedelta\n","from google.colab import drive\n","try:\n","    import pandas_ta as ta  # optional; we fall back to manual if missing/quirky\n","except Exception:\n","    ta = None\n","\n","# --- CONNECT GOOGLE DRIVE ---\n","drive.mount('/content/drive')\n","\n","# --- API KEY ---\n","# Prefer setting this in Colab (Runtime → Run all, then re-run) or via:\n","# os.environ[\"POLYGON_API_KEY\"] = \"YOUR_KEY_HERE\"\n","POLYGON_API_KEY = os.environ.get(\"POLYGON_API_KEY\", \"fbrZKMMbLhV7p0Rz_C9PKM69eps7P8OG\")\n","if POLYGON_API_KEY == \"REPLACE_ME\" or not POLYGON_API_KEY:\n","    raise RuntimeError(\"Set POLYGON_API_KEY in environment before running.\")\n","\n","# --- OUTPUT DIR ---\n","OUT_DIR = \"/content/drive/MyDrive/polygon_hourly_5y_multi\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","# --- TICKERS TO DOWNLOAD (edit this list) ---\n","TICKERS = [\"AAPL\",\"MSFT\",\"NVDA\",\"AMD\",\"JPM\",\"GS\",\"XOM\",\"CVX\",\"PG\",\"KO\"]\n","\n","# --- DATE RANGE: last 5 years up to today (UTC) ---\n","end_date  = pd.Timestamp.utcnow().normalize().strftime(\"%Y-%m-%d\")\n","start_date = (pd.Timestamp.utcnow().normalize() - pd.DateOffset(years=5)).strftime(\"%Y-%m-%d\")\n","\n","# --- CORE DOWNLOAD (Polygon aggs) ---\n","def download_polygon_data(ticker: str,\n","                          start_date: str,\n","                          end_date: str,\n","                          multiplier: int = 1,\n","                          timespan: str = \"hour\",\n","                          adjusted: bool = True,\n","                          sleep_s: float = 0.15) -> pd.DataFrame:\n","    key = POLYGON_API_KEY\n","    base_url = f\"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/{multiplier}/{timespan}/{start_date}/{end_date}\"\n","    params = {\"adjusted\": str(adjusted).lower(), \"sort\": \"asc\", \"limit\": 50000, \"apiKey\": key}\n","\n","    all_rows = []\n","    url = base_url\n","    print(f\"[DL] {ticker}: {timespan} {start_date}→{end_date}\")\n","    while True:\n","        r = requests.get(url, params=params if url == base_url else None, timeout=60)\n","        if r.status_code != 200:\n","            raise RuntimeError(f\"[DL_ERR] {ticker} HTTP {r.status_code}: {r.text[:200]}\")\n","        data = r.json()\n","        if data.get(\"status\") not in (\"OK\",\"DELAYED\"):\n","            raise RuntimeError(f\"[DL_ERR] {ticker} bad status: {data.get('status')} {data}\")\n","        results = data.get(\"results\", [])\n","        for x in results:\n","            all_rows.append({\n","                \"timestamp\": pd.to_datetime(x[\"t\"], unit=\"ms\", utc=True),\n","                \"open\": float(x[\"o\"]),\n","                \"high\": float(x[\"h\"]),\n","                \"low\": float(x[\"l\"]),\n","                \"close\": float(x[\"c\"]),\n","                \"volume\": float(x[\"v\"]),\n","                \"vwap\": float(x[\"vw\"]) if x.get(\"vw\") is not None else None\n","            })\n","        next_url = data.get(\"next_url\")\n","        if not next_url:\n","            break\n","        # polygon returns next_url without apiKey param sometimes\n","        if \"apiKey=\" not in next_url:\n","            next_url += (\"&\" if \"?\" in next_url else \"?\") + f\"apiKey={key}\"\n","        url = next_url\n","        time.sleep(sleep_s)\n","\n","    df = pd.DataFrame(all_rows).sort_values(\"timestamp\").reset_index(drop=True)\n","    print(f\"[DL] {ticker}: {len(df)} rows\")\n","    return df\n","\n","# --- FEATURES (3 only): price_change_pct, MACDh_12_26_9, BBM_20_2.0 ---\n","def add_selected_features(df: pd.DataFrame) -> pd.DataFrame:\n","    # 1) price_change_pct\n","    df[\"price_change_pct\"] = df[\"close\"].pct_change() * 100.0\n","\n","    # 2) MACD histogram (MACDh_12_26_9)\n","    macdh_col = \"MACDh_12_26_9\"\n","    try:\n","        if ta is not None:\n","            df.ta.macd(fast=12, slow=26, signal=9, append=True)  # adds MACD_*, MACDh_*, MACDs_*\n","            if macdh_col not in df.columns:\n","                macd_col, macds_col = \"MACD_12_26_9\", \"MACDs_12_26_9\"\n","                if macd_col in df.columns and macds_col in df.columns:\n","                    df[macdh_col] = df[macd_col] - df[macds_col]\n","                else:\n","                    raise RuntimeError(\"pandas_ta MACD columns missing\")\n","        else:\n","            raise RuntimeError(\"pandas_ta not available\")\n","    except Exception:\n","        # Manual MACD → MACD histogram\n","        ema12 = df[\"close\"].ewm(span=12, adjust=False).mean()\n","        ema26 = df[\"close\"].ewm(span=26, adjust=False).mean()\n","        macd = ema12 - ema26\n","        signal = macd.ewm(span=9, adjust=False).mean()\n","        df[macdh_col] = macd - signal\n","\n","    # 3) BBM_20_2.0 (Bollinger middle band = SMA20)\n","    df[\"BBM_20_2.0\"] = df[\"close\"].rolling(window=20, min_periods=20).mean()\n","\n","    # Keep only required columns (ensure presence)\n","    keep = [\"timestamp\",\"open\",\"high\",\"low\",\"close\",\"volume\",\"vwap\",\n","            \"price_change_pct\",\"MACDh_12_26_9\",\"BBM_20_2.0\"]\n","    keep = [c for c in keep if c in df.columns]\n","    out = df[keep].dropna().reset_index(drop=True)\n","    return out\n","\n","# --- Ensure VWAP exists; if all NA, approximate with rolling TWAP-like proxy ---\n","def ensure_vwap(df: pd.DataFrame, lookback: int = 20) -> pd.DataFrame:\n","    if \"vwap\" not in df.columns or df[\"vwap\"].isna().all():\n","        # proxy using rolling (vol*close)/vol; for hourly, this is a simple fallback\n","        vol_roll = df[\"volume\"].rolling(window=lookback, min_periods=1).sum()\n","        vc_roll  = (df[\"volume\"] * df[\"close\"]).rolling(window=lookback, min_periods=1).sum()\n","        df[\"vwap\"] = vc_roll / vol_roll\n","    else:\n","        # fill small holes if any\n","        df[\"vwap\"] = df[\"vwap\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n","    return df\n","\n","# --- MAIN BATCH ---\n","manifest = []\n","errors   = {}\n","\n","for tkr in TICKERS:\n","    try:\n","        raw = download_polygon_data(tkr, start_date, end_date, multiplier=1, timespan=\"hour\", adjusted=True)\n","        if raw.empty:\n","            print(f\"[WARN] {tkr}: no data returned; skipping\")\n","            errors[tkr] = \"no_data\"\n","            continue\n","\n","        raw = ensure_vwap(raw)\n","        feat = add_selected_features(raw.copy())\n","\n","        save_path = os.path.join(OUT_DIR, f\"{tkr}_hourly_last5y_selected_features.csv\")\n","        feat.to_csv(save_path, index=False)\n","        print(f\"[SAVE] {tkr}: {save_path}  rows={len(feat)}\")\n","\n","        manifest.append({\n","            \"ticker\": tkr,\n","            \"rows\": len(feat),\n","            \"path\": save_path,\n","            \"start\": feat[\"timestamp\"].iloc[0].isoformat(),\n","            \"end\":   feat[\"timestamp\"].iloc[-1].isoformat(),\n","            \"cols\": list(feat.columns)\n","        })\n","\n","        # light pacing to respect rate limits\n","        time.sleep(0.25)\n","\n","    except Exception as e:\n","        print(f\"[ERR] {tkr}: {e}\")\n","        errors[tkr] = str(e)\n","\n","# --- Write a small manifest JSON in the same folder ---\n","man_path = os.path.join(OUT_DIR, \"download_manifest.json\")\n","with open(man_path, \"w\") as f:\n","    json.dump({\"tickers\": TICKERS, \"manifest\": manifest, \"errors\": errors}, f, indent=2)\n","print(f\"[DONE] Manifest saved: {man_path}\")\n","print(f\"[SUMMARY] ok={len(manifest)} err={len(errors)}\")\n"]}]}